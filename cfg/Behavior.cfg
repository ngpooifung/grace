#!/usr/bin/env python
PACKAGE = 'r2_behavior'

from dynamic_reconfigure.parameter_generator_catkin import *
import yaml_config

gen = ParameterGenerator()

gen.add("enable_flag", bool_t, 0, "enable behaviors", True)
gen.add("synthesizer_rate",double_t,0,"rate at which behavior is synthesized (Hz.)",10.0,1.0,100.0)

eye_contact_enum = gen.enum([
  gen.const("IDLE",int_t,0,"IDLE: do not make eye contact"),
  gen.const("LEFT_EYE",int_t,1,"LEFT_EYE: look at left eye"),
  gen.const("RIGHT_EYE",int_t,2,"RIGHT_EYE: look at right eye"),
  gen.const("BOTH_EYES",int_t,3,"BOTH_EYES: switch between looking at left eye and right eye"),
  gen.const("TRIANGLE",int_t,4,"TRIANGLE: switch between looking at left eye, right eye and mouth")
],"eye contact state")

gen.add("eyecontact_state",int_t,0,"eye contact state",0,0,4,edit_method=eye_contact_enum)

lookat_enum = gen.enum([
  gen.const("IDLE",int_t,0,"IDLE: not looking at anything"),
  gen.const("AVOID",int_t,1,"AVOID: avoid looking at anything"),
  gen.const("SALIENCY",int_t,2,"SALIENCY: look at generally interesting things"),
  gen.const("ONE_FACE",int_t,3,"ONE_FACE: look at the current face"),
  gen.const("ALL_FACES",int_t,4,"ALL_FACES: switch between looking at all faces"),
  gen.const("AUDIENCE",int_t,5,"AUDIENCE: switch between looking at the audience"),
  gen.const("SPEAKER",int_t,6,"SPEAKER: look at the speaker")
],"lookat state")

gen.add("lookat_state",int_t,0,"lookat state",0,0,7,edit_method=lookat_enum)

mirroring_enum = gen.enum([
  gen.const("IDLE",int_t,0,"IDLE: no mirroring"),
  gen.const("EYEBROWS",int_t,1,"EYEBROWS: mirror the eyebrows"),
  gen.const("EYELIDS",int_t,2,"EYELIDS: mirror the eyelids (blinking)"),
  gen.const("EYES",int_t,3,"EYES: mirror eyebrows and eyelids"),
  gen.const("MOUTH",int_t,4,"MOUTH: mirror the mouth opening and closing"),
  gen.const("MOUTH_EYEBROWS",int_t,5,"MOUTH_EYEBROWS: mirror the eyebrows and mouth opening and closing"),
  gen.const("MOUTH_EYELIDS",int_t,6,"MOUTH_EYELIDS: mirror the eyelids (blinking) and mouth opening and closing"),
  gen.const("ALL",int_t,7,"ALL: mirror the eyebrows, eyelids (blinking) and mouth opening and closing")
],"mirroring state")

gen.add("mirroring_state",int_t,0,"mirroring state",0,0,7,edit_method=mirroring_enum)

gaze_enum = gen.enum([
  gen.const("GAZE_ONLY",int_t,0,"GAZE_ONLY: only adjust gaze direction"),
  gen.const("HEAD_ONLY",int_t,1,"HEAD_ONLY: only adjust head direction"),
  gen.const("GAZE_AND_HEAD",int_t,2,"GAZE_AND_HEAD: adjust both gaze and head directions"),
  gen.const("GAZE_LEADS_HEAD",int_t,3,"GAZE_LEADS_HEAD: first adjust gaze, and after some delay slowly adjust head"),
  gen.const("HEAD_LEADS_GAZE",int_t,4,"HEAD_LEADS_GAZE: first adjust head, and after some delay slowly adjust gaze")
],"gaze state")

gen.add("gaze_state",int_t,0,"gaze state",0,0,4,edit_method=gaze_enum)

state_enum = gen.enum([
  gen.const("SLEEPING",int_t,0,"SLEEPING: the robot sleeps"),
  gen.const("IDLE",int_t,1,"IDLE: the robot is idle"),
  gen.const("INTERESTED",int_t,2,"INTERESTED: the robot is actively idle"),
  gen.const("FOCUSED",int_t,3,"FOCUSED: the robot is very interested in something specific"),
  gen.const("SPEAKING",int_t,4,"SPEAKING: the robot is to one or more persons or the speaker"),
  gen.const("LISTENING",int_t,5,"LISTENING: the robot is listening to whoever is speaking"),
  gen.const("PRESENTING",int_t,6,"PRESENTING: the robot is presenting to an audience")
],"main state")

gen.add("state",int_t,0,"main robot state (controls the other states)",0,0,6,edit_method=state_enum)

gen.add("keep_time",double_t,0,"time to keep observations around as useful (sec.)",0.5,0.1,10.0)
gen.add("saliency_time_min",double_t,0,"minimum time between each saliency switch (sec.)",0.5,0.1,10.0)
gen.add("saliency_time_max",double_t,0,"maximum time between each saliency switch (sec.)",2.0,0.1,10.0)
gen.add("faces_time_min",double_t,0,"minimum time between each face switch (sec.)",0.5,0.1,10.0)
gen.add("faces_time_max",double_t,0,"maximum time between each face switch (sec.)",2.0,0.1,10.0)
gen.add("eyes_time_min",double_t,0,"minimum time between each eye switch (sec.)",0.5,0.1,10.0)
gen.add("eyes_time_max",double_t,0,"maximum time between each eye switch (sec.)",2.0,0.1,10.0)
gen.add("audience_time_min",double_t,0,"minimum time between each audience switch (sec.)",0.5,0.1,10.0)
gen.add("audience_time_max",double_t,0,"maximum time between each audience switch (sec.)",2.0,0.1,10.0)
gen.add("gesture_time_min",double_t,0,"minimum time between the start of two gestures (sec.)",0.5,0.1,20.0)
gen.add("gesture_time_max",double_t,0,"maximum time between the start of two gestures (sec.)",2.0,0.1,20.0)
gen.add("expression_time_min",double_t,0,"minimum time between the start of two expressions (sec.)",0.5,0.1,20.0)
gen.add("expression_time_max",double_t,0,"maximum time between the start of two expressions (sec.)",2.0,0.1,20.0)
gen.add("face_state_decay",double_t,0,"time before returning to IDLE after having talked/seen a face (sec.)",2.0,0.5,20.0)
gen.add("gaze_delay",double_t,0,"gaze following delay time (sec.)",1.0,0.5,20.0)
gen.add("gaze_speed",double_t,0,"speed setting for following gaze/head adjustments",0.5,0.5,20.0)
gen.add("all_faces_start_time_min",double_t,0,"minimum time between addressing all faces during SPEAKING state (sec.)",4.0,0.5,20.0)
gen.add("all_faces_start_time_max",double_t,0,"maximum time between addressing all faces during SPEAKING state (sec.)",6.0,0.5,20.0)
gen.add("all_faces_duration_min",double_t,0,"minimum duration of addressing all faces during SPEAKING state (sec.)",2.0,0.5,20.0)
gen.add("all_faces_duration_max",double_t,0,"maximum duration of addressing all faces during SPEAKING state (sec.)",4.0,0.5,20.0)
gen.add("reload_animations", bool_t, 0, "reload expressions and gestures", True)

# gestures = yaml_config.load('gestures_schema' or '{}')
# expressions = yaml_config.load('expressions_schema' or '{}')
# node_schema = {
#   'sleeping_gestures':    gestures,
#   'sleeping_expressions': expressions,
#   'idle_gestures':    gestures,
#   'idle_expressions': expressions,
#   'interested_gestures':    gestures,
#   'interested_expressions': expressions,
#   'focused_gestures':    gestures,
#   'focused_expressions': expressions,
#   'speaking_gestures':    gestures,
#   'speaking_expressions': expressions,
#   'listening_gestures':    gestures,
#   'listening_expressions': expressions,
#   'presenting_gestures':    gestures,
#   'presenting_expressions': expressions,
# }
#
#
# gen.add("sleeping_gestures", str_t, 0, 'SLEEPING gestures', 'NOTSET')
# gen.add("sleeping_expressions", str_t, 0, 'SLEEPING expressions', 'NOTSET')
#
# gen.add("idle_gestures", str_t, 0, 'IDLE gestures', 'NOTSET')
# gen.add("idle_expressions", str_t, 0, 'IDLE expressions', 'NOTSET')
#
# gen.add("interested_gestures", str_t, 0, 'INTERESTED gestures', 'NOTSET')
# gen.add("interested_expressions", str_t, 0, 'INTERESTED expressions', 'NOTSET')
#
# gen.add("focused_gestures", str_t, 0, 'FOCUSED gestures', 'NOTSET')
# gen.add("focused_expressions", str_t, 0, 'FOCUSED expressions', 'NOTSET')
#
#
# gen.add("speaking_gestures", str_t, 0, 'SPEAKING gestures', 'NOTSET')
# gen.add("speaking_expressions", str_t, 0, 'SPEAKING expressions', 'NOTSET')
#
# gen.add("listening_gestures", str_t, 0, 'LISTENING gestures', 'NOTSET')
# gen.add("listening_expressions", str_t, 0, 'LISTENING expressions', 'NOTSET')
#
# gen.add("presenting_gestures", str_t, 0, 'PRESENTING gestures', 'NOTSET')
# gen.add("presenting_expressions", str_t, 0, 'PRESENTING expressions', 'NOTSET')
#
#
#
# gen.add("node_schema", str_t, 0, 'Behavior', json.dumps(node_schema))


exit(gen.generate(PACKAGE, "behavior", "Behavior"))
